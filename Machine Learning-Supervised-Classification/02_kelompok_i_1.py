# -*- coding: utf-8 -*-
"""02-Kelompok I-1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1duKZeL7HR3ew9XHTVIDQyO4LQve4CtSs

# Assignment Chapter 2 - MACHINE LEARNING [Case #1]
Startup Campus, Indonesia - `Artificial Intelligence (AI)` (Batch 7)
* Dataset: SC_HW1_bank_data
* Libraries: Pandas, Numpy, Scikit-learn
* Objective: Classification with Supervised Machine Learning Models

`PERSYARATAN` Semua modul (termasuk versi yang sesuai) sudah di-install dengan benar.
<br>`CARA PENGERJAAN` Lengkapi baris kode yang ditandai dengan **#TODO**.
<br>`TARGET PORTFOLIO` Peserta mampu membandingkan akurasi klasifikasi dari berbagai model *supervised learning*.

### Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split as tts
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ParameterGrid

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

from sklearn.linear_model import LogisticRegression
# from imblearn.over_sampling import SMOTE
# from imblearn.under_sampling import RandomUnderSampler

"""### Read Dataset"""

np.random.seed(123)

df = pd.read_csv('https://raw.githubusercontent.com/Rietaros/kampus_merdeka/main/SC_HW1_bank_data.csv')
df.columns

df.info()

df.head()

df.groupby('Exited').size()

# TODO: Hilangkan kolom yang tidak relevan untuk pemodelan

df = df.drop(['RowNumber', 'CustomerId'], axis=1).copy()
df.head()

"""### Preprocessing"""

# TODO: Lakukan One-Hot Encoder untuk data kategorikal, dengan fungsi pd.get_dummies
df = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True, dtype=int)
df.head()

# TODO: Pisahkan fitur (X) dengan target (Y), dimana Y merujuk ke kolom "Exited"
X = df.drop(['Exited'], axis=1)
y = df['Exited']
X.head()

# scaler = ... # TODO: Lakukan scaling atau normalisasi
# X_transform = scaler.fit_transform(X)

# Normalisasi dilakukan setelah split data train dan test

# Bagian ini digunakan jika Anda melakukan scaling atau normalisasi.
# Jika tidak, code ini bisa dilewati dan diganti dengan code yang ada di dalam comment.

# X_transform= pd.DataFrame(X_transform, columns = X.columns)
# X_transform = X.copy()

"""### Train-Test Split"""

X_train ,X_test, y_train, y_test = tts(X, y, test_size = 0.25, random_state = 123)
X_train.head()

# standarisasi data training dan data testing
scaler = StandardScaler()
# scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""### Model #1"""

# [ PERTANYAAN ]
# TODO: Jelaskan secara singkat model #1 yang Anda gunakan.

"""[ ANSWER HERE ]
<br>Logistic Regression adalah salah satu algoritma machine laearning yang cukup populer untuk kasus klasifikasi biner. Untuk mencari hyperparameter terbaik, digunakan gridsearchcv dengan beberapa hyparameter yang dirasa cocok untuk kasus dan kondisi yang ada.
"""

# CONTOH pemanggilan library dan penggunaannya:

# from sklearn.linear_model import LogisticRegression
# model1 = LogisticRegression()
# params = {"tol": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}


# TODO: Pilih salah satu model Machine Learning (ML) dari Scikit-learn
from sklearn.neural_network import MLPClassifier

mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=123, max_iter=500)
mlp.fit(X_train, y_train)

# params = None

# OPTIONAL: Lakukan hyperparameter tuning sesuai kebutuhan
# grid = GridSearchCV(
#     estimator= model1,
#     param_grid= params,
#     scoring = 'accuracy',
#     n_jobs = 10, # core cpu yang digunakan
#     cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)
# )

# grid.fit(X_train,y_train)
# grid.best_params_

# TODO: Lakukan evaluasi untuk model #1
y_pred = mlp.predict(X_test)

print(classification_report(y_test,y_pred))
print("")
print(confusion_matrix(y_test,y_pred))
print("")
print(accuracy_score(y_test, y_pred))

# model KNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
params ={
    'n_neighbors': [1, 3, 5, 7, 10],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan'],
    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],
}

grid = GridSearchCV(
    estimator =knn,
    param_grid =params,
    scoring = 'accuracy',
    n_jobs = 10, # core cpu yang digunakan
    cv = 10
)
grid.fit(X_train, y_train)
y_pred = grid.predict(X_test)


print(classification_report(y_test,y_pred))
print("")
print(confusion_matrix(y_test,y_pred))
print("")
print(accuracy_score(y_test, y_pred))

"""### Model #2"""

# [ PERTANYAAN ]
# TODO: Jelaskan secara singkat model #2 yang Anda gunakan.

"""[ ANSWER HERE ]
<br>SVC bekerja dengan cara mencari hyperplane antar kelas. Algoritma SVC ini sangat cocok untuk data yang memiliki dimensi tinggi (memiliki banyak fitur) seperti pada kasus yang pada soal ini yang memiliki 10 fitur. SVC akan mengubah seluruh data menjadi vektor baru kemudian dilanjutkan dengan mencari batas antar kelas yang disebut hyperplane. Untuk mencari hyperplane anatar kelas dilakukan dengan menggunakan kernel trick (memilih kernel yang sesuai) agar klasifikasi memiliki tingkat akurasi dan presisi yang baik. Pada kasus ini, kernel yang digunakan adalah kernel default (Radial Basis Function) karena kernel tersebut menghasilkan model dengan performa yang lebih baik dibanding kernel lain
"""

# CONTOH pemanggilan library dan penggunaannya:

# from sklearn.linear_model import LogisticRegression
# model1 = LogisticRegression()
# params = {"tol": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}


# TODO: Pilih salah satu model Machine Learning (ML) dari Scikit-learn
from sklearn.svm import SVC
model2 = SVC(random_state=123)
model2.fit(X_train, y_train)


# OPTIONAL: Lakukan hyperparameter tuning sesuai kebutuhan
# grid = GridSearchCV(
#     estimator = model2,
#     param_grid = params,
#     scoring = 'accuracy',
#     n_jobs = 10, # core cpu yang digunakan
#     cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)
# )

# grid.fit(X_train, y_train)
# grid.best_params_

y_pred = model2.predict(X_test) # TODO: Lakukan evaluasi untuk model #2

print(classification_report(y_test,y_pred))
print("")
print(confusion_matrix(y_test,y_pred))
print("")
print(accuracy_score(y_test, y_pred))

"""### Model #3"""

# [ PERTANYAAN ]
# TODO: Jelaskan secara singkat model #3 yang Anda gunakan.

"""[ ANSWER HERE ]
<br>Random Forest adalah salah satu model machine learning yang memiliki resiko overfitting yang lebih rendah. Pada model yang dibuat, digunakan hyperparameter gini sebagai criterion dan untuk menentukan fitur yang digunakan pada tiap pohon menggunakan akar n. Pada model ini juga dilakukan tuning pada hyperparameter class_weight karena terjadi imbalanced data. Dengan mengatur class_weight, random forest dapat menyesuaikan dengan data yang tidak seimbang.
"""

# CONTOH pemanggilan library dan penggunaannya:

# from sklearn.linear_model import LogisticRegression
# model1 = LogisticRegression()
# params = {"tol": [0.1,0.01,0.001], 'C':[0.5,1.0,1.5,2.0]}


# TODO: Pilih salah satu model Machine Learning (ML) dari Scikit-learn
from sklearn.ensemble import RandomForestClassifier
model3 = RandomForestClassifier(
    criterion='gini',
    class_weight='balanced',
    max_features='sqrt',
    random_state=123,
    n_estimators=200
)
model3.fit(X_train, y_train)


# OPTIONAL: Lakukan hyperparameter tuning sesuai kebutuhan
# grid = GridSearchCV(
#     estimator= model3,
#     param_grid= params,
#     scoring = 'accuracy',
#     n_jobs = 10, # core cpu yang digunakan
#     cv = 10 # 3-fold cross validation (artinya kita melakukan iterasi model sebanyak 3 kali)
# )

# grid.fit(X_train,y_train)
# grid.best_params_

y_pred = model3.predict(X_test) # TODO: Lakukan evaluasi untuk model #3

print(classification_report(y_test,y_pred))
print("")
print(confusion_matrix(y_test,y_pred))
print("")
print(accuracy_score(y_test, y_pred))

"""### Conclusion"""

# [ PERTANYAAN ]
# TODO: Tarik kesimpulan model mana yang terbaik beserta alasannya

"""[ ANSWER HERE ]

### Scoring
Total `#TODO` = 13
<br>Checklist:

- [ ] Hilangkan kolom yang tidak relevan untuk pemodelan
- [ ] Lakukan One-Hot Encoder untuk data kategorikal, dengan fungsi pd.get_dummies
- [ ] Pisahkan fitur (X) dengan target (Y), dimana Y merujuk ke kolom "Exited"
- [ ] Lakukan scaling atau normalisasi
- [ ] Jelaskan secara singkat model #1 yang Anda gunakan
- [ ] Pilih salah satu model Machine Learning (ML) dari Scikit-learn (model #1)
- [ ] Lakukan evaluasi untuk model #1
- [ ] Jelaskan secara singkat model #2 yang Anda gunakan
- [ ] Pilih salah satu model Machine Learning (ML) dari Scikit-learn (model #2)
- [ ] Lakukan evaluasi untuk model #2
- [ ] Jelaskan secara singkat model #3 yang Anda gunakan
- [ ] Pilih salah satu model Machine Learning (ML) dari Scikit-learn (model #3)
- [ ] Lakukan evaluasi untuk model #3

### Additional readings
- N/A

### Copyright Â© 2024 Startup Campus, Indonesia
* You may **NOT** use this file except there is written permission from PT. Kampus Merdeka Belajar (Startup Campus).
* Please address your questions to mentors.
"""